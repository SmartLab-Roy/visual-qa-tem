{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c1fec9-72d0-411e-943f-e09a7b615789",
   "metadata": {},
   "source": [
    "### Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "732f9751-5774-4e9f-bcdf-ba83f3b635e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T08:00:11.663540Z",
     "iopub.status.busy": "2025-07-24T08:00:11.663382Z",
     "iopub.status.idle": "2025-07-24T08:00:11.842609Z",
     "shell.execute_reply": "2025-07-24T08:00:11.842145Z",
     "shell.execute_reply.started": "2025-07-24T08:00:11.663527Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a18180-0734-4b7c-99b9-bfa9a588634d",
   "metadata": {},
   "source": [
    "### Define the parse function dealing with json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b56a18-336d-4967-99c1-18b579ab07c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_parse_json(raw):\n",
    "    try:\n",
    "        if pd.isna(raw) or raw.strip() in ['\"\"', \"''\", '[]', '']:\n",
    "            return []\n",
    "        \n",
    "        cleaned = raw.strip()\n",
    "\n",
    "        #delete markdown format\n",
    "        if cleaned.startswith(\"```json\"):\n",
    "            cleaned = cleaned[len(\"```json\"):].strip()\n",
    "        if cleaned.startswith(\"```\"):\n",
    "            cleaned = cleaned[len(\"```\"):].strip()\n",
    "        if cleaned.endswith(\"```\"):\n",
    "            cleaned = cleaned[:-3].strip()\n",
    "\n",
    "        return json.loads(cleaned)\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db8dce4-6e5f-42c6-bb23-e3f355c12837",
   "metadata": {},
   "source": [
    "### Parse the replys from the distilled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d441cf-306b-44e1-b5dc-d70ccfc0cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load distilled data CSV ===\n",
    "file_path = \"gpt_reply_log.csv\"\n",
    "\n",
    "# === Read CSV and parse 'reply' column as JSON ===\n",
    "df = pd.read_csv(file_path)\n",
    "df[\"reply_json\"] = df[\"reply\"].apply(clean_and_parse_json)\n",
    "\n",
    "# === Basic statistics ===\n",
    "total = len(df)\n",
    "success = df[\"reply_json\"].notnull().sum()\n",
    "failure = df[\"reply_json\"].isnull().sum()\n",
    "failed_indices = df[df[\"reply_json\"].isnull()].index.tolist()\n",
    "\n",
    "print(f\"successfully parse: {success}\")\n",
    "print(f\"failly parse: {failure}\")\n",
    "print(f\"Failed indices (first 10): {failed_indices[:10]}\")\n",
    "\n",
    "# === Extract successfully parsed entries ===\n",
    "df_success = df[df[\"reply_json\"].notnull()]\n",
    "success_data = df_success[\"reply_json\"].tolist()\n",
    "\n",
    "# Save them into JSON format\n",
    "with open(\"success.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(success_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# # === Extract failed entries for manual debugging ===\n",
    "# df_failure = df[df[\"reply_json\"].isnull()]\n",
    "# failure_data = df_failure[\"reply\"].tolist()\n",
    "\n",
    "# # # Save them into a text file for manual inspection\n",
    "# with open(\"failure.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     for entry in failure_data:\n",
    "#         f.write(str(entry) + \"\\n\\n---\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c7d772-4e44-4b24-b0cf-9e1ecfc94d17",
   "metadata": {},
   "source": [
    "### Split train/val dataset depend on sub-image groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f89863f-b742-42d2-9a72-49fe7e9fb327",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T08:00:20.657936Z",
     "iopub.status.busy": "2025-07-24T08:00:20.657749Z",
     "iopub.status.idle": "2025-07-24T08:00:21.940939Z",
     "shell.execute_reply": "2025-07-24T08:00:21.940488Z",
     "shell.execute_reply.started": "2025-07-24T08:00:20.657926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Split complete: train = 33813 images, val = 5966 images\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the parsed QA dataset from success.json\n",
    "with open(\"success.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 2. Group QA pairs by sub_image (one entry per image)\n",
    "image_to_qas = {}\n",
    "for qa_list in data:\n",
    "    if not isinstance(qa_list, list):\n",
    "        continue\n",
    "    for qa in qa_list:\n",
    "        image = qa.get(\"sub_image\", \"\").strip()\n",
    "        if image:\n",
    "            image_to_qas.setdefault(image, []).append(qa)\n",
    "\n",
    "# 3. Set a fixed random seed for reproducibility, and select 15% of images for validation\n",
    "random.seed(42)\n",
    "all_images = list(image_to_qas.keys())\n",
    "val_size = max(1, int(0.15 * len(all_images)))\n",
    "val_images = set(random.sample(all_images, val_size))\n",
    "\n",
    "# 4. Split QA pairs into training and validation sets based on image grouping\n",
    "train_data, val_data = [], []\n",
    "for image, qas in image_to_qas.items():\n",
    "    if image in val_images:\n",
    "        val_data.append(qas)\n",
    "    else:\n",
    "        train_data.append(qas)\n",
    "\n",
    "# 5. Save the training and validation sets to JSON files\n",
    "with open(\"train_set.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(train_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "with open(\"val_set.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(val_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Split complete: train = {len(train_data)} images, val = {len(val_data)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8544ae62-0536-4658-be5b-2174efdcc2fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T08:01:39.355399Z",
     "iopub.status.busy": "2025-07-24T08:01:39.354958Z",
     "iopub.status.idle": "2025-07-24T08:01:39.908880Z",
     "shell.execute_reply": "2025-07-24T08:01:39.908627Z",
     "shell.execute_reply.started": "2025-07-24T08:01:39.355385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Converted and saved to val_llava_flat.json. Total samples: 38103\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the training data (nested QA format grouped by image)\n",
    "with open(\"val_set.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "\n",
    "# 2. Initialize container for the flattened results\n",
    "flattened_data = []\n",
    "\n",
    "# 3. Flatten each QA pair into an independent LLaVA-style sample\n",
    "for qa_list in raw_data:\n",
    "    if not isinstance(qa_list, list):\n",
    "        continue\n",
    "    for qa in qa_list:\n",
    "        image_path = qa.get(\"sub_image\", \"\").strip()\n",
    "        question = qa.get(\"question\", \"\").strip()\n",
    "        answer = qa.get(\"answer\", \"\").strip()\n",
    "        level = qa.get(\"level\", None)\n",
    "\n",
    "        flattened_data.append({\n",
    "            \"image\": image_path,\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": f\"<image>\\n {question}\",\n",
    "                    \"level\": level\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": answer,\n",
    "                    \"level\": level\n",
    "                }\n",
    "            ]\n",
    "        })\n",
    "\n",
    "# 4. Save the result in LLaVA-compatible format (flattened per QA pair)\n",
    "with open(\"val_llava_flat.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(flattened_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ Converted and saved to val_llava_flat.json. Total samples:\", len(flattened_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46cfff4b-9f9d-49e4-a607-4f869e698ac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T08:01:49.262517Z",
     "iopub.status.busy": "2025-07-24T08:01:49.262368Z",
     "iopub.status.idle": "2025-07-24T08:01:49.930901Z",
     "shell.execute_reply": "2025-07-24T08:01:49.930408Z",
     "shell.execute_reply.started": "2025-07-24T08:01:49.262506Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Exported: val/val_Classification.json (9131 samples)\n",
      "[✓] Exported: val/val_Recognition.json (11652 samples)\n",
      "[✓] Exported: val/val_Reasoning.json (11586 samples)\n",
      "[✓] Exported: val/val_Summary.json (5685 samples)\n"
     ]
    }
   ],
   "source": [
    "# === Configuration ===\n",
    "input_path = \"val_llava_flat.json\"\n",
    "output_prefix = \"val_\"\n",
    "\n",
    "# Difficulty level mapping from numeric level to string labe\n",
    "level_mapping = {1: \"Classification\", 2: \"Recognition\", 3: \"Reasoning\", 4: \"Summary\"}\n",
    "\n",
    "# === Step 1: Load the original dataset ===\n",
    "with open(input_path, \"r\") as f:    data = json.load(f)\n",
    "\n",
    "# === Step 2: Organize data by different types and reformat ===\n",
    "standard_by_level = defaultdict(list)\n",
    "id_counters = defaultdict(int)\n",
    "\n",
    "for item in data:\n",
    "    try:\n",
    "        # Extract the level number and convert it to a difficulty label\n",
    "        level_num = item[\"conversations\"][0].get(\"level\")\n",
    "        level_str = level_mapping.get(level_num)\n",
    "        if not level_str:\n",
    "            continue\n",
    "\n",
    "        # Extract the image filename (no path)\n",
    "        image_name = item[\"image\"].split(\"/\")[-1]\n",
    "\n",
    "        # Reformat the item into standard format with a custom ID\n",
    "        standard_item = {\n",
    "            \"id\": f\"{level_str.upper()}_{id_counters[level_str]:06d}\",\n",
    "            \"image\": image_name,\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": item[\"conversations\"][0][\"value\"]\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": item[\"conversations\"][1][\"value\"]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        # Append to corresponding level list\n",
    "        standard_by_level[level_str].append(standard_item)\n",
    "        id_counters[level_str] += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Skipped problematic entry:\", e)\n",
    "        continue\n",
    "\n",
    "# === Step 3: Save the reformatted data by difficulty level ===\n",
    "for level_str, items in standard_by_level.items():\n",
    "    output_path = f\"val/{output_prefix}{level_str}.json\"\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(items, f, indent=2)\n",
    "    print(f\"[✓] Exported: {output_path} ({len(items)} samples)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9364755a-bdbe-41d0-842f-09803c16d9f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# === Path Configuration ===\n",
    "json_path = \"success_filtered.json\"  # Input JSON file with nested QA format\n",
    "source_dir = \"/home/ne6131039/Desktop/TEM_DATAS/LLaVA Dataset/TEM_images\"\n",
    "target_dir = \"/home/ne6131039/Desktop/LLaVA_train\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# === Step 1: Load success.json ===\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === Step 2: Collect all unique image filenames from 'sub_image'\n",
    "image_names = set()\n",
    "for qa_list in data:\n",
    "    if not isinstance(qa_list, list):\n",
    "        continue\n",
    "    for qa in qa_list:\n",
    "        image = qa.get(\"sub_image\", \"\").strip()\n",
    "        filename = image.split(\"/\")[-1]\n",
    "        if filename:\n",
    "            image_names.add(filename)\n",
    "\n",
    "print(f\"Total unique images to copy: {len(image_names)}\")\n",
    "\n",
    "# === Step 3: Copy images from source_dir to target_dir\n",
    "missing = []\n",
    "for img in image_names:\n",
    "    src = os.path.join(source_dir, img)\n",
    "    dst = os.path.join(target_dir, img)\n",
    "    if os.path.exists(src):\n",
    "        # shutil.copyfile(src, dst)\n",
    "        continue\n",
    "    else:\n",
    "        missing.append(img)\n",
    "\n",
    "# === Step 4: Summary\n",
    "print(f\"Copy completed: {len(image_names) - len(missing)} images copied successfully.\")\n",
    "if missing:\n",
    "    print(f\"Missing {len(missing)} images. Examples: {missing[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5bc491-6c23-4f6a-8248-3e6ecb9063ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Step 4: Filter out QA groups with any missing sub_image inside ===\n",
    "# missing_set = set(missing)\n",
    "# filtered_data = []\n",
    "\n",
    "# for group in data:\n",
    "#     if not isinstance(group, list) or not group:\n",
    "#         continue\n",
    "\n",
    "#     # 確認整個 group 所有 sub_image 都不在 missing_set\n",
    "#     group_images = {qa.get(\"sub_image\", \"\").strip().split(\"/\")[-1] for qa in group}\n",
    "#     if not group_images & missing_set:\n",
    "#         filtered_data.append(group)\n",
    "\n",
    "# # === Step 5: Save filtered JSON ===\n",
    "# with open(\"success_filtered.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(filtered_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# # === Final Summary ===\n",
    "# print(f\"Copy completed: {len(image_names) - len(missing)} images copied successfully.\")\n",
    "# if missing:\n",
    "#     print(f\"Missing {len(missing)} images. Examples: {missing[:5]}\")\n",
    "# print(f\"Filtered JSON saved with {len(filtered_data)} image groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34814b39-b657-4b25-8b23-31b1a2f251f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ocr_env)",
   "language": "python",
   "name": "ocr_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
