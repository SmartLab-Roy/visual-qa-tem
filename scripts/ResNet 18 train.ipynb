{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e50b33-99c1-4bae-814f-3e25ef874f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# è¨­å®šè³‡æ–™é›†æ ¹ç›®éŒ„\n",
    "dataset_root = '/home/ne6131039/Desktop/TEM_DATAS/TEM_classification'  # ä¿®æ”¹æˆä½ è‡ªå·±çš„è³‡æ–™å¤¾è·¯å¾‘\n",
    "\n",
    "# å–å¾—åˆ†é¡è³‡æ–™å¤¾åˆ—è¡¨\n",
    "categories = ['CTEM', 'HR-TEM', 'STEM', 'SEM', 'None', 'Diffraction']\n",
    "\n",
    "# çµ±è¨ˆæ¯å€‹è³‡æ–™å¤¾çš„åœ–ç‰‡æ•¸é‡\n",
    "for category in categories:\n",
    "    folder_path = os.path.join(dataset_root, category)\n",
    "    if os.path.exists(folder_path):\n",
    "        file_count = len([\n",
    "            f for f in os.listdir(folder_path)\n",
    "            if os.path.isfile(os.path.join(folder_path, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ])\n",
    "        print(f'{category:12s}: {file_count} images')\n",
    "    else:\n",
    "        print(f'{category:12s}: è³‡æ–™å¤¾ä¸å­˜åœ¨')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd31cf47-babd-4279-9f2b-243f3979c914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import random\n",
    "\n",
    "# éœ€è¦å¢å¼·çš„é¡åˆ¥\n",
    "augment_categories = ['HR-TEM', 'STEM', 'Diffraction']\n",
    "dataset_root = '/home/ne6131039/Desktop/TEM_DATAS/TEM_classification'\n",
    "\n",
    "# æ¯å¼µåœ–é¡å¤–ç”¢ç”Ÿå¹¾å¼µå¢å¼·åœ–\n",
    "augment_count = 3\n",
    "\n",
    "# å®šç¾©å¢å¼·æ–¹æ³•ï¼ˆå¯ä¾éœ€æ±‚èª¿æ•´ï¼‰\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),  # å¯ä»¥æ›æˆ Resize\n",
    "])\n",
    "\n",
    "for category in augment_categories:\n",
    "    folder_path = os.path.join(dataset_root, category)\n",
    "    images = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    for image_name in images:\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"ç„¡æ³•è®€å– {image_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        for i in range(augment_count):\n",
    "            aug_img = augmentation(image)\n",
    "            new_name = f\"{os.path.splitext(image_name)[0]}_aug{i}.jpg\"\n",
    "            new_path = os.path.join(folder_path, new_name)\n",
    "            aug_img.save(new_path)\n",
    "\n",
    "        print(f\"âœ… å·²å¢å¼·: {image_name} -> {augment_count} å¼µ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fff7a0-d4d6-49c6-9c12-a1b7e684683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# åŸå§‹è³‡æ–™é›†è·¯å¾‘ï¼ˆå…­é¡æ”¾ä¸€èµ·ï¼‰\n",
    "src_root = '/home/ne6131039/Desktop/TEM_DATAS/TEM_classification'\n",
    "\n",
    "# æ–°çš„è³‡æ–™å¤¾çµæ§‹\n",
    "dst_root = '/home/ne6131039/Desktop/TEM_DATAS/TEM_split'\n",
    "splits = ['train', 'val', 'test']\n",
    "split_ratio = {'train': 0.7, 'val': 0.15, 'test': 0.15}\n",
    "\n",
    "categories = ['CTEM', 'HR-TEM', 'STEM', 'SEM', 'None', 'Diffraction']\n",
    "\n",
    "# å»ºç«‹è³‡æ–™å¤¾çµæ§‹\n",
    "for split in splits:\n",
    "    for category in categories:\n",
    "        os.makedirs(os.path.join(dst_root, split, category), exist_ok=True)\n",
    "\n",
    "# åˆ†å‰²è³‡æ–™\n",
    "for category in categories:\n",
    "    src_folder = os.path.join(src_root, category)\n",
    "    images = [f for f in os.listdir(src_folder) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    random.shuffle(images)\n",
    "\n",
    "    train_end = int(len(images) * split_ratio['train'])\n",
    "    val_end = train_end + int(len(images) * split_ratio['val'])\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        if i < train_end:\n",
    "            split = 'train'\n",
    "        elif i < val_end:\n",
    "            split = 'val'\n",
    "        else:\n",
    "            split = 'test'\n",
    "\n",
    "        src_path = os.path.join(src_folder, img)\n",
    "        dst_path = os.path.join(dst_root, split, category, img)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "\n",
    "    print(f\"{category:12s}: train={train_end}, val={val_end-train_end}, test={len(images)-val_end}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ab8594-2274-4f03-b20d-0b6ffdb2ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# åŸå§‹å…­é¡åˆ†é¡è³‡æ–™å¤¾\n",
    "src_root = '/home/ne6131039/Desktop/TEM_DATAS/TEM_split'\n",
    "# æ–°çš„äºŒåˆ†é¡è³‡æ–™å¤¾\n",
    "dst_root = '/home/ne6131039/Desktop/TEM_DATAS/TEM_binary'\n",
    "\n",
    "# ä¸‰å€‹åˆ†å‰²å€\n",
    "splits = ['train', 'val', 'test']\n",
    "none_label = 'None'\n",
    "all_categories = ['CTEM', 'HR-TEM', 'STEM', 'SEM', 'Diffraction', 'None']\n",
    "\n",
    "# å»ºç«‹ç›®æ¨™è³‡æ–™å¤¾çµæ§‹\n",
    "for split in splits:\n",
    "    for label in ['None', 'NotNone']:\n",
    "        os.makedirs(os.path.join(dst_root, split, label), exist_ok=True)\n",
    "\n",
    "# é–‹å§‹åˆ†é¡æ¬ç§»è³‡æ–™\n",
    "for split in splits:\n",
    "    for category in all_categories:\n",
    "        src_folder = os.path.join(src_root, split, category)\n",
    "        if not os.path.exists(src_folder):\n",
    "            continue\n",
    "\n",
    "        # æ±ºå®šé€™å€‹åˆ†é¡å±¬æ–¼ None or NotNone\n",
    "        target_label = 'None' if category == none_label else 'NotNone'\n",
    "        dst_folder = os.path.join(dst_root, split, target_label)\n",
    "\n",
    "        for fname in os.listdir(src_folder):\n",
    "            if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                src_path = os.path.join(src_folder, fname)\n",
    "                dst_path = os.path.join(dst_folder, f\"{category}_{fname}\")\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "\n",
    "        print(f\"[{split}] {category} -> {target_label}, å®Œæˆæ¬ç§»\")\n",
    "\n",
    "print(\"âœ… äºŒåˆ†é¡è³‡æ–™é›†ç”¢ç”Ÿå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf3a175-a244-439e-8a8d-37eedeedaf13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====== è¨­å®šåƒæ•¸ ======\n",
    "data_root = '/home/ne6131039/Desktop/TEM_DATAS/TEM_binary'\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "initial_lr = 0.0001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ====== åœ–åƒè½‰æ› ======\n",
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "    ])\n",
    "}\n",
    "\n",
    "# ====== è¼‰å…¥è³‡æ–™é›† ======\n",
    "datasets_binary = {\n",
    "    x: datasets.ImageFolder(os.path.join(data_root, x), transform=transform[x])\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "dataloaders = {\n",
    "    x: DataLoader(datasets_binary[x], batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "class_names = datasets_binary['train'].classes\n",
    "print(\"é¡åˆ¥æ¨™ç±¤å°æ‡‰ï¼š\", class_names)\n",
    "\n",
    "# ====== å»ºç«‹æ¨¡å‹ ======\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "model = model.to(device)\n",
    "\n",
    "# ====== Optimizer & Scheduler ======\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# ====== è¨˜éŒ„è¨“ç·´è³‡æ–™ ======\n",
    "loss_history = []\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "lr_history = []\n",
    "best_val_acc = 0.0\n",
    "best_model_path = \"best_binary_classifier.pth\"\n",
    "\n",
    "# ====== è¨“ç·´ä¸»è¿´åœˆ ======\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    running_loss, running_corrects, total = 0.0, 0, 0\n",
    "\n",
    "    for inputs, labels in tqdm(dataloaders['train'], desc=\"Training\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = running_corrects.double() / total\n",
    "\n",
    "    # é©—è­‰éšæ®µ\n",
    "    model.eval()\n",
    "    val_corrects, val_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['val']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_acc = val_corrects.double() / val_total\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # æ›´æ–°æœ€ä½³æ¨¡å‹\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"âœ… å„²å­˜æœ€ä½³æ¨¡å‹ (Val Acc: {val_acc:.2%})\")\n",
    "\n",
    "    # ç´€éŒ„æ•¸æ“š\n",
    "    loss_history.append(train_loss)\n",
    "    train_acc_history.append(train_acc.item())\n",
    "    val_acc_history.append(val_acc.item())\n",
    "    lr_history.append(current_lr)\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2%} | Val Acc: {val_acc:.2%} | LR: {current_lr:.6f}\")\n",
    "\n",
    "# ====== ç¹ªè£½åœ–å½¢ä¸¦å„²å­˜ ======\n",
    "epochs = list(range(1, num_epochs + 1))\n",
    "fig, axs = plt.subplots(4, 1, figsize=(8, 12))\n",
    "\n",
    "axs[0].plot(epochs, loss_history, color='red', marker='o')\n",
    "axs[0].set_title(\"Training Loss over Epochs\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].grid(True)\n",
    "\n",
    "axs[1].plot(epochs, train_acc_history, color='orange', marker='o')\n",
    "axs[1].set_title(\"Training Accuracy over Epochs\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Accuracy\")\n",
    "axs[1].grid(True)\n",
    "\n",
    "axs[2].plot(epochs, val_acc_history, color='blue', marker='o')\n",
    "axs[2].set_title(\"Validation Accuracy over Epochs\")\n",
    "axs[2].set_xlabel(\"Epoch\")\n",
    "axs[2].set_ylabel(\"Accuracy\")\n",
    "axs[2].grid(True)\n",
    "\n",
    "axs[3].plot(epochs, lr_history, color='green', marker='o')\n",
    "axs[3].set_title(\"Learning Rate over Epochs\")\n",
    "axs[3].set_xlabel(\"Epoch\")\n",
    "axs[3].set_ylabel(\"Learning Rate\")\n",
    "axs[3].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"training_metrics_summary.png\")\n",
    "print(\"ğŸ“Š å·²å„²å­˜è¨“ç·´éç¨‹åœ–ï¼štraining_metrics_summary.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71646ae-f0ca-4094-8dce-7f3f2a2cb351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# ====== åƒæ•¸è¨­å®š ======\n",
    "test_dir = '/home/ne6131039/Desktop/TEM_DATAS/TEM_binary/test'\n",
    "model_path = 'best_binary_classifier.pth'\n",
    "batch_size = 32\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ====== åœ–åƒé è™•ç† ======\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# ====== è¼‰å…¥æ¸¬è©¦è³‡æ–™é›† ======\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "class_names = test_dataset.classes\n",
    "print(\"åˆ†é¡æ¨™ç±¤ï¼š\", class_names)\n",
    "\n",
    "# ====== è¼‰å…¥æ¨¡å‹ä¸¦è½‰ç§»è‡³ GPU ======\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 2)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ====== æ¨è«–ä¸¦ç´€éŒ„çµæœ ======\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# ====== æ•´é«”æº–ç¢ºç‡ ======\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "acc = (all_preds == all_labels).sum() / len(all_labels)\n",
    "print(f\"âœ… æ¸¬è©¦æº–ç¢ºç‡ï¼š{acc:.2%}\")\n",
    "\n",
    "# ====== æ··æ·†çŸ©é™£èˆ‡å ±å‘Š ======\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Test Set)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"test_confusion_matrix.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“‹ è©³ç´°åˆ†é¡å ±å‘Š:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ef7e5-406c-412d-8e4d-4c442f051491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====== è¨­å®šåƒæ•¸ ======\n",
    "data_root = '/home/ne6131039/Desktop/TEM_DATAS/TEM_split'\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "initial_lr = 0.0001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ====== åœ–åƒè½‰æ› ======\n",
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "    ])\n",
    "}\n",
    "\n",
    "# ====== è¼‰å…¥è³‡æ–™é›† ======\n",
    "datasets_multi = {\n",
    "    x: datasets.ImageFolder(os.path.join(data_root, x), transform=transform[x])\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "dataloaders = {\n",
    "    x: DataLoader(datasets_multi[x], batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "class_names = datasets_multi['train'].classes\n",
    "num_classes = len(class_names)\n",
    "print(\"äº”é¡æ¨™ç±¤ï¼š\", class_names)\n",
    "\n",
    "# ====== å»ºç«‹æ¨¡å‹ ======\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# ====== Lossã€Optimizerã€Scheduler ======\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# ====== è¨˜éŒ„è¨“ç·´è³‡æ–™ ======\n",
    "loss_history = []\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "lr_history = []\n",
    "best_val_acc = 0.0\n",
    "best_model_path = \"best_five_class_classifier.pth\"\n",
    "\n",
    "# ====== è¨“ç·´ä¸»è¿´åœˆ ======\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    running_loss, running_corrects, total = 0.0, 0, 0\n",
    "\n",
    "    for inputs, labels in tqdm(dataloaders['train'], desc=\"Training\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = running_corrects.double() / total\n",
    "\n",
    "    # é©—è­‰éšæ®µ\n",
    "    model.eval()\n",
    "    val_corrects, val_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['val']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_acc = val_corrects.double() / val_total\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"âœ… å„²å­˜æœ€ä½³æ¨¡å‹ (Val Acc: {val_acc:.2%})\")\n",
    "\n",
    "    loss_history.append(train_loss)\n",
    "    train_acc_history.append(train_acc.item())\n",
    "    val_acc_history.append(val_acc.item())\n",
    "    lr_history.append(current_lr)\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2%} | Val Acc: {val_acc:.2%} | LR: {current_lr:.6f}\")\n",
    "\n",
    "# ====== ç¹ªåœ–ä¸¦å„²å­˜ ======\n",
    "epochs = list(range(1, num_epochs + 1))\n",
    "fig, axs = plt.subplots(4, 1, figsize=(8, 12))\n",
    "\n",
    "axs[0].plot(epochs, loss_history, color='red', marker='o')\n",
    "axs[0].set_title(\"Training Loss over Epochs\")\n",
    "\n",
    "axs[1].plot(epochs, train_acc_history, color='orange', marker='o')\n",
    "axs[1].set_title(\"Training Accuracy over Epochs\")\n",
    "\n",
    "axs[2].plot(epochs, val_acc_history, color='blue', marker='o')\n",
    "axs[2].set_title(\"Validation Accuracy over Epochs\")\n",
    "\n",
    "axs[3].plot(epochs, lr_history, color='green', marker='o')\n",
    "axs[3].set_title(\"Learning Rate over Epochs\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"five_class_training_metrics.png\")\n",
    "print(\"ğŸ“Š å·²å„²å­˜äº”é¡è¨“ç·´åœ–ï¼šfive_class_training_metrics.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398efdff-787f-41bf-aee2-a7f228a0bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# ====== è·¯å¾‘è¨­å®š ======\n",
    "test_dir = '/home/ne6131039/Desktop/TEM_DATAS/TEM_split/test'\n",
    "model_path = 'best_five_class_classifier.pth'\n",
    "batch_size = 32\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ====== åœ–åƒè½‰æ› ======\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# ====== è¼‰å…¥æ¸¬è©¦é›† ======\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "class_names = test_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(\"æ¸¬è©¦é¡åˆ¥é †åºï¼š\", class_names)\n",
    "\n",
    "# ====== å»ºç«‹æ¨¡å‹ & è¼‰å…¥æ¬Šé‡ ======\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ====== æ¨è«–æ‰€æœ‰æ¸¬è©¦è³‡æ–™ ======\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "acc = (all_preds == all_labels).sum() / len(all_labels)\n",
    "print(f\"\\nâœ… æ¸¬è©¦æº–ç¢ºç‡ï¼š{acc:.2%}\")\n",
    "\n",
    "# ====== æ··æ·†çŸ©é™£ ======\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix (Five-Class Test)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"five_class_test_confusion_matrix.png\")\n",
    "plt.show()\n",
    "\n",
    "# ====== è©³ç´°å ±å‘Š ======\n",
    "print(\"\\nğŸ“‹ è©³ç´°åˆ†é¡å ±å‘Šï¼š\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109b763-5724-48e0-bbfc-d9690c965b80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TEM_project)",
   "language": "python",
   "name": "tem_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
